# ML-Model-Comparison-Research

Overview
Deep learning (DL) has become a popular technique for classifying cloud of data. A move that risen concerns on the reliability of DL and its comparison to traditional machine learning models. By definition, DL relies on learning to improve its accuracy suggesting that it is unequipped to provide accurate data under unfamiliar circumstance. This paper will attempt to explore how deep learning compare to other machine models and human in regards to reliability when placed under similar conditions.
Reliability, according to the standards set by IEEE, is defined as “the probability of failure-free software operation for a specified period of time in a specified environment”. With this in mind, we decided to measure the reliability of machine learning model as the accuracy and precision of its predictions. The thought behind this idea is that if the model was implemented into physical machine, the accuracy and precision of the model would determine the likelihood of safe software operations.
To investigate the performance of the various model, a case study consisting of the classification of breast cancer will be conducted. Each model will be given a dataset with significant contributing attributes and they must be able to identify whether the cancer is benign or malignant. The data will be obtained from the open source database Beast Cancer Wisconsin Data Set from the University of Wisconsin Hospital in Madison, Wisconsin. The purpose of the project is not improve that models but determine accuracy of the results.
The paper will conclude on a deep analysis of the various techniques and a comparison of the reliability of each based on its accuracy to provide reliable data. The goal of the paper is to provide empirical data that can either support or oppose the use of deep learning in determining critical function such as cancer detection.
